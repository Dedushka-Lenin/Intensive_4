{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a61e194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 00:27:17,471 - INFO - Данные успешно загружены.\n",
      "2025-05-21 00:27:17,475 - INFO - Разделение данных выполнено успешно.\n",
      "2025-05-21 00:27:17,858 - INFO - Веса классов: [ 4.35071088 10.06862736  2.85324231  1.52572707  6.14556959  3.78389829]\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Epoch 1/15: 100%|██████████| 71/71 [13:28<00:00, 11.38s/batch]\n",
      "2025-05-21 00:40:47,236 - INFO - Эпоха 1/15 - Средний Loss: 1.1075\n",
      "Validation Epoch 1: 100%|██████████| 18/18 [00:42<00:00,  2.35s/batch]\n",
      "2025-05-21 00:41:32,799 - INFO - Новая лучшая модель сохранена по F1 macro: 0.3250\n",
      "2025-05-21 00:41:36,413 - INFO - Новая лучшая модель по F1 micro сохранена: 0.3163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 1 - F1 macro: 0.3250, F1 micro: 0.3163\n",
      "F1-score для 'Вопрос решен': 0.3217\n",
      "F1-score для 'Нравится качество выполнения заявки': 0.2740\n",
      "F1-score для 'Нравится качество работы сотрудников': 0.5664\n",
      "F1-score для 'Нравится скорость отработки заявок': 0.0000\n",
      "F1-score для 'Понравилось выполнение заявки': 0.2038\n",
      "F1-score для 'Другое': 0.5843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|██████████| 71/71 [13:10<00:00, 11.13s/batch]\n",
      "2025-05-21 00:54:46,610 - INFO - Эпоха 2/15 - Средний Loss: 0.8492\n",
      "Validation Epoch 2: 100%|██████████| 18/18 [00:42<00:00,  2.34s/batch]\n",
      "2025-05-21 00:55:32,125 - INFO - Новая лучшая модель сохранена по F1 macro: 0.5885\n",
      "2025-05-21 00:55:35,780 - INFO - Новая лучшая модель по F1 micro сохранена: 0.6029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 2 - F1 macro: 0.5885, F1 micro: 0.6029\n",
      "F1-score для 'Вопрос решен': 0.4476\n",
      "F1-score для 'Нравится качество выполнения заявки': 0.2485\n",
      "F1-score для 'Нравится качество работы сотрудников': 0.8466\n",
      "F1-score для 'Нравится скорость отработки заявок': 0.8611\n",
      "F1-score для 'Понравилось выполнение заявки': 0.3521\n",
      "F1-score для 'Другое': 0.7752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|██████████| 71/71 [3:06:00<00:00, 157.19s/batch]    \n",
      "2025-05-21 04:01:36,236 - INFO - Эпоха 3/15 - Средний Loss: 0.6064\n",
      "Validation Epoch 3: 100%|██████████| 18/18 [00:41<00:00,  2.32s/batch]\n",
      "2025-05-21 04:02:21,472 - INFO - Новая лучшая модель сохранена по F1 macro: 0.6123\n",
      "2025-05-21 04:02:25,289 - INFO - Новая лучшая модель по F1 micro сохранена: 0.6590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 3 - F1 macro: 0.6123, F1 micro: 0.6590\n",
      "F1-score для 'Вопрос решен': 0.4771\n",
      "F1-score для 'Нравится качество выполнения заявки': 0.3200\n",
      "F1-score для 'Нравится качество работы сотрудников': 0.8375\n",
      "F1-score для 'Нравится скорость отработки заявок': 0.8909\n",
      "F1-score для 'Понравилось выполнение заявки': 0.4035\n",
      "F1-score для 'Другое': 0.7445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|██████████| 71/71 [13:12<00:00, 11.16s/batch]\n",
      "2025-05-21 04:15:37,629 - INFO - Эпоха 4/15 - Средний Loss: 0.4967\n",
      "Validation Epoch 4: 100%|██████████| 18/18 [00:41<00:00,  2.33s/batch]\n",
      "2025-05-21 04:16:22,865 - INFO - Новая лучшая модель сохранена по F1 macro: 0.6321\n",
      "2025-05-21 04:16:26,346 - INFO - Новая лучшая модель по F1 micro сохранена: 0.6796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 4 - F1 macro: 0.6321, F1 micro: 0.6796\n",
      "F1-score для 'Вопрос решен': 0.4717\n",
      "F1-score для 'Нравится качество выполнения заявки': 0.3226\n",
      "F1-score для 'Нравится качество работы сотрудников': 0.8742\n",
      "F1-score для 'Нравится скорость отработки заявок': 0.8950\n",
      "F1-score для 'Понравилось выполнение заявки': 0.4356\n",
      "F1-score для 'Другое': 0.7937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|██████████| 71/71 [4:32:12<00:00, 230.04s/batch]    \n",
      "2025-05-21 08:48:39,008 - INFO - Эпоха 5/15 - Средний Loss: 0.4101\n",
      "Validation Epoch 5: 100%|██████████| 18/18 [00:41<00:00,  2.33s/batch]\n",
      "2025-05-21 08:49:24,291 - INFO - Новая лучшая модель сохранена по F1 macro: 0.6641\n",
      "2025-05-21 08:49:28,079 - INFO - Новая лучшая модель по F1 micro сохранена: 0.7167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 5 - F1 macro: 0.6641, F1 micro: 0.7167\n",
      "F1-score для 'Вопрос решен': 0.5417\n",
      "F1-score для 'Нравится качество выполнения заявки': 0.4691\n",
      "F1-score для 'Нравится качество работы сотрудников': 0.8831\n",
      "F1-score для 'Нравится скорость отработки заявок': 0.9115\n",
      "F1-score для 'Понравилось выполнение заявки': 0.3960\n",
      "F1-score для 'Другое': 0.7833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100%|██████████| 71/71 [13:28<00:00, 11.39s/batch]\n",
      "2025-05-21 09:02:56,458 - INFO - Эпоха 6/15 - Средний Loss: 0.3186\n",
      "Validation Epoch 6: 100%|██████████| 18/18 [00:42<00:00,  2.37s/batch]\n",
      "2025-05-21 09:03:42,759 - INFO - Новая лучшая модель по F1 micro сохранена: 0.7275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 6 - F1 macro: 0.6609, F1 micro: 0.7275\n",
      "F1-score для 'Вопрос решен': 0.5143\n",
      "F1-score для 'Нравится качество выполнения заявки': 0.5000\n",
      "F1-score для 'Нравится качество работы сотрудников': 0.9032\n",
      "F1-score для 'Нравится скорость отработки заявок': 0.9107\n",
      "F1-score для 'Понравилось выполнение заявки': 0.3750\n",
      "F1-score для 'Другое': 0.7619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100%|██████████| 71/71 [13:19<00:00, 11.26s/batch]\n",
      "2025-05-21 09:17:02,353 - INFO - Эпоха 7/15 - Средний Loss: 0.2748\n",
      "Validation Epoch 7: 100%|██████████| 18/18 [00:42<00:00,  2.35s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 7 - F1 macro: 0.6534, F1 micro: 0.7179\n",
      "F1-score для 'Вопрос решен': 0.4286\n",
      "F1-score для 'Нравится качество выполнения заявки': 0.5231\n",
      "F1-score для 'Нравится качество работы сотрудников': 0.8790\n",
      "F1-score для 'Нравится скорость отработки заявок': 0.9140\n",
      "F1-score для 'Понравилось выполнение заявки': 0.4220\n",
      "F1-score для 'Другое': 0.7538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: 100%|██████████| 71/71 [13:18<00:00, 11.25s/batch]\n",
      "2025-05-21 09:31:03,545 - INFO - Эпоха 8/15 - Средний Loss: 0.2332\n",
      "Validation Epoch 8: 100%|██████████| 18/18 [00:42<00:00,  2.34s/batch]\n",
      "2025-05-21 09:31:49,015 - INFO - Новая лучшая модель сохранена по F1 macro: 0.6712\n",
      "2025-05-21 09:31:52,317 - INFO - Новая лучшая модель по F1 micro сохранена: 0.7356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 8 - F1 macro: 0.6712, F1 micro: 0.7356\n",
      "F1-score для 'Вопрос решен': 0.4848\n",
      "F1-score для 'Нравится качество выполнения заявки': 0.5625\n",
      "F1-score для 'Нравится качество работы сотрудников': 0.8805\n",
      "F1-score для 'Нравится скорость отработки заявок': 0.8987\n",
      "F1-score для 'Понравилось выполнение заявки': 0.4301\n",
      "F1-score для 'Другое': 0.7705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: 100%|██████████| 71/71 [13:22<00:00, 11.31s/batch]\n",
      "2025-05-21 09:45:15,006 - INFO - Эпоха 9/15 - Средний Loss: 0.2183\n",
      "Validation Epoch 9: 100%|██████████| 18/18 [00:42<00:00,  2.37s/batch]\n",
      "2025-05-21 09:46:01,128 - INFO - Новая лучшая модель по F1 micro сохранена: 0.7367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 9 - F1 macro: 0.6711, F1 micro: 0.7367\n",
      "F1-score для 'Вопрос решен': 0.4950\n",
      "F1-score для 'Нравится качество выполнения заявки': 0.5294\n",
      "F1-score для 'Нравится качество работы сотрудников': 0.8931\n",
      "F1-score для 'Нравится скорость отработки заявок': 0.8987\n",
      "F1-score для 'Понравилось выполнение заявки': 0.4301\n",
      "F1-score для 'Другое': 0.7805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: 100%|██████████| 71/71 [13:19<00:00, 11.26s/batch]\n",
      "2025-05-21 09:59:20,761 - INFO - Эпоха 10/15 - Средний Loss: 0.1685\n",
      "Validation Epoch 10: 100%|██████████| 18/18 [00:42<00:00,  2.35s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 10 - F1 macro: 0.6662, F1 micro: 0.7228\n",
      "F1-score для 'Вопрос решен': 0.5000\n",
      "F1-score для 'Нравится качество выполнения заявки': 0.6071\n",
      "F1-score для 'Нравится качество работы сотрудников': 0.8931\n",
      "F1-score для 'Нравится скорость отработки заявок': 0.8969\n",
      "F1-score для 'Понравилось выполнение заявки': 0.3564\n",
      "F1-score для 'Другое': 0.7438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: 100%|██████████| 71/71 [13:20<00:00, 11.27s/batch]\n",
      "2025-05-21 10:13:23,213 - INFO - Эпоха 11/15 - Средний Loss: 0.1531\n",
      "Validation Epoch 11: 100%|██████████| 18/18 [00:42<00:00,  2.36s/batch]\n",
      "2025-05-21 10:14:05,654 - INFO - Ранняя остановка: достигнут patience без улучшения.\n",
      "2025-05-21 10:14:06,057 - INFO - Загружена лучшая модель по F1 macro.\n",
      "2025-05-21 10:14:06,058 - WARNING - Не удалось загрузить модель по micro: [Errno 2] No such file or directory: 'best_bert_multilabel_f2micro.pth'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import logging\n",
    "from tqdm import tqdm  # импорт прогресс-бара\n",
    "\n",
    "# Настройка логирования\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# 1. Загрузка данных\n",
    "try:\n",
    "    data = pd.read_csv('processed_data.csv')  # путь к вашему файлу с данными\n",
    "    logging.info(\"Данные успешно загружены.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Ошибка при загрузке данных: {e}\")\n",
    "    raise\n",
    "\n",
    "# 3. Предобработка данных: приведение к нижнему регистру и очистка\n",
    "categories = [\n",
    "    'Вопрос решен',\n",
    "    'Нравится качество выполнения заявки',\n",
    "    'Нравится качество работы сотрудников',\n",
    "    'Нравится скорость отработки заявок',\n",
    "    'Понравилось выполнение заявки',\n",
    "    'Другое'\n",
    "]\n",
    "\n",
    "try:\n",
    "    labels = data[categories].values.astype(int)\n",
    "except KeyError as e:\n",
    "    logging.error(f\"Некоторые категории не найдены в данных: {e}\")\n",
    "    raise\n",
    "\n",
    "# 4. Разделение на обучающую и валидационную выборки с стратификацией по первому классу\n",
    "try:\n",
    "    stratify_labels = labels.argmax(axis=1)\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "        data['comment'].values,\n",
    "        labels,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=stratify_labels\n",
    "    )\n",
    "    logging.info(\"Разделение данных выполнено успешно.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Ошибка при разделении данных: {e}\")\n",
    "    raise\n",
    "\n",
    "# 5. Токенизация и подготовка датасета с русской моделью BERT\n",
    "model_name = 'DeepPavlov/rubert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "class CommentsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=256):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length= max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text= str(self.texts[idx])\n",
    "        label= self.labels[idx]\n",
    "        try:\n",
    "            encoding= self.tokenizer.encode_plus(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_length,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            input_ids= encoding['input_ids'].squeeze(0)\n",
    "            attention_mask= encoding['attention_mask'].squeeze(0)\n",
    "            return {\n",
    "                'input_ids': input_ids,\n",
    "                'attention_mask': attention_mask,\n",
    "                'labels': torch.FloatTensor(label)\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Ошибка при токенизации текста: {e}\")\n",
    "            return {\n",
    "                'input_ids': torch.zeros(self.max_length,dtype=torch.long),\n",
    "                'attention_mask': torch.zeros(self.max_length,dtype=torch.long),\n",
    "                'labels': torch.FloatTensor(label)\n",
    "            }\n",
    "\n",
    "train_dataset = CommentsDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = CommentsDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "class_counts= train_labels.sum(axis=0)\n",
    "total_samples= len(train_labels)\n",
    "\n",
    "epsilon=1e-6\n",
    "class_weights = (total_samples - class_counts + epsilon) / (class_counts + epsilon)\n",
    "class_weights_tensor= torch.FloatTensor(class_weights)\n",
    "logging.info(f\"Веса классов: {class_weights}\")\n",
    "\n",
    "# 6. Создаем веса для балансировки (для использования в WeightedRandomSampler)\n",
    "sample_weights=[]\n",
    "for label in train_labels:\n",
    "    class_indices= np.where(label==1)[0]\n",
    "    weights_for_classes = class_weights[class_indices] if len(class_indices)>0 else np.array([1.0])\n",
    "    sample_weight= np.min(weights_for_classes) \n",
    "    sample_weights.append(sample_weight)\n",
    "\n",
    "sample_weights=np.array(sample_weights)\n",
    "\n",
    "sampler= WeightedRandomSampler(weights= sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "train_loader= DataLoader(train_dataset, batch_size=16, sampler=sampler)\n",
    "val_loader= DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# 7. Модель с несколькими выходами (multi-label)\n",
    "class BertMultiLabelClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.3):\n",
    "        super(BertMultiLabelClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, len(categories))\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output  \n",
    "        pooled_output= self.dropout(pooled_output)\n",
    "        logits= self.classifier(pooled_output)  \n",
    "        return logits\n",
    "\n",
    "device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model= BertMultiLabelClassifier()\n",
    "model.to(device)\n",
    "\n",
    "criterion= nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor)\n",
    "\n",
    "optimizer= optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "num_epochs=15  \n",
    "total_steps= len(train_loader)*num_epochs\n",
    "\n",
    "scheduler= get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.1*total_steps),\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "best_f1_score_on_val = 0  # для сохранения лучшей модели\n",
    "\n",
    "# Параметры ранней остановки (например: patience - сколько эпох ждать без улучшения)\n",
    "patience = 3 \n",
    "epochs_without_improvement = 0\n",
    "\n",
    "# Инициализация переменной для лучшего значения F1 micro\n",
    "best_f1_micro = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Прогресс-бар по батчам с tqdm\n",
    "    with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\", unit='batch') as pbar:\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            try:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # градиентный клиппинг для стабилизации обучения\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Ошибка во время обучения батча {batch_idx}: {e}\")\n",
    "\n",
    "            pbar.update(1)  # обновляем прогресс-бар\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    logging.info(f\"Эпоха {epoch+1}/{num_epochs} - Средний Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # --- Валидация ---\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds=[]\n",
    "    all_true=[]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx,batch in enumerate(tqdm(val_loader,f\"Validation Epoch {epoch+1}\", unit='batch')):\n",
    "            try:\n",
    "                input_ids=batch['input_ids'].to(device)\n",
    "                attention_mask=batch['attention_mask'].to(device)\n",
    "                labels=batch['labels'].cpu().numpy()\n",
    "\n",
    "                outputs=model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                preds=torch.sigmoid(outputs).cpu().numpy()\n",
    "\n",
    "                all_preds.extend(preds)\n",
    "                all_true.extend(labels)\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Ошибка при обработке батча {batch_idx}: {e}\")\n",
    "\n",
    "    true_labels=np.array(all_true) \n",
    "    preds_array=np.array(all_preds) \n",
    "\n",
    "    pred_labels=(preds_array>=0.5).astype(int)\n",
    "\n",
    "    # Вычисляем F1-score на валидации после каждой эпохи\n",
    "    try:\n",
    "        f1_macro=f1_score(true_labels,pred_labels,average='macro')\n",
    "        f1_micro=f1_score(true_labels,pred_labels,average='micro')  # добавляем расчет F1 micro\n",
    "        \n",
    "        # Проверка и сохранение модели по F1 macro\n",
    "        if f1_macro > best_f1_score_on_val:\n",
    "            best_f1_score_on_val=f1_macro\n",
    "            epochs_without_improvement=0\n",
    "            \n",
    "            torch.save(model.state_dict(),'best_bert_multilabel.pth')\n",
    "            logging.info(f\"Новая лучшая модель сохранена по F1 macro: {f1_macro:.4f}\")\n",
    "        \n",
    "        else:\n",
    "            epochs_without_improvement+=1\n",
    "\n",
    "        # Проверка и сохранение модели по F1 micro\n",
    "        if f1_micro > best_f1_micro:\n",
    "            best_f1_micro=f1_micro\n",
    "            # Можно сохранить отдельную модель или перезаписать ту же\n",
    "            torch.save(model.state_dict(),'best_bert_multilabel_f1micro.pth')\n",
    "            logging.info(f\"Новая лучшая модель по F1 micro сохранена: {f1_micro:.4f}\")\n",
    "\n",
    "        # Ранняя остановка при отсутствии улучшений по macro\n",
    "        if epochs_without_improvement >= patience:\n",
    "            logging.info(\"Ранняя остановка: достигнут patience без улучшения.\")\n",
    "            break\n",
    "        \n",
    "        print(f\"\\nЭпоха {epoch+1} - F1 macro: {f1_macro:.4f}, F1 micro: {f1_micro:.4f}\")\n",
    "        \n",
    "        # Вывод по классам (по желанию)\n",
    "        for i,cate in enumerate(categories):\n",
    "            try:\n",
    "                score=f1_score(true_labels[:,i],pred_labels[:,i])\n",
    "                print(f\"F1-score для '{cate}': {score:.4f}\")\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Ошибка при вычислении F1 для '{cate}': {e}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Ошибка во время оценки или обучения: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d8c1903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 12:00:43,841 - INFO - Модель загружена.\n"
     ]
    }
   ],
   "source": [
    "# После завершения обучения можно загрузить лучшую модель по macro или по micro\n",
    "# try:\n",
    "#     model.load_state_dict(torch.load('best_bert_multilabel.pth'))\n",
    "#     logging.info(\"Загружена лучшая модель по F1 macro.\")\n",
    "# except Exception as e:\n",
    "#     logging.warning(f\"Не удалось загрузить модель по macro: {e}\")\n",
    "\n",
    "# Или загрузить модель с наилучшим показателем по micro (если нужно)\n",
    "try:\n",
    "    model.load_state_dict(torch.load('best_bert_multilabel_f1micro.pth'))\n",
    "    logging.info(\"Модель загружена.\")\n",
    "except Exception as e:\n",
    "    logging.warning(f\"Не удалось загрузить модель: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6b1c9adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score для 'Вопрос решен': 0.4950\n",
      "F1-score для 'Нравится качество выполнения заявки': 0.5294\n",
      "F1-score для 'Нравится качество работы сотрудников': 0.8931\n",
      "F1-score для 'Нравится скорость отработки заявок': 0.8987\n",
      "F1-score для 'Понравилось выполнение заявки': 0.4301\n",
      "F1-score для 'Другое': 0.7805\n",
      "\n",
      "Средний F1-score (macro): 0.6711\n",
      "F1-score (micro): 0.7367\n",
      "--------------------------------------------------------------------------\n",
      "ROC-AUC для 'Вопрос решен': 0.7590\n",
      "ROC-AUC для 'Нравится качество выполнения заявки': 0.8845\n",
      "ROC-AUC для 'Нравится качество работы сотрудников': 0.9663\n",
      "ROC-AUC для 'Нравится скорость отработки заявок': 0.9593\n",
      "ROC-AUC для 'Понравилось выполнение заявки': 0.7998\n",
      "ROC-AUC для 'Другое': 0.9196\n",
      "\n",
      "Средний ROC-AUC по классам: 0.8814\n"
     ]
    }
   ],
   "source": [
    "# Оценка модели на валидационной выборке с обработкой ошибок и логированием\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_true = []\n",
    "\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(val_loader):\n",
    "            try:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].cpu().numpy()\n",
    "\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "\n",
    "                all_preds.extend(preds)\n",
    "                all_true.extend(labels)\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Ошибка при обработке батча {batch_idx}: {e}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Ошибка во время оценки: {e}\")\n",
    "\n",
    "true_labels = np.array(all_true)  # shape: (num_samples,num_classes)\n",
    "preds_array = np.array(all_preds)\n",
    "\n",
    "pred_labels = (preds_array >= 0.5).astype(int)\n",
    "\n",
    "try:\n",
    "    f1_macro = f1_score(true_labels, pred_labels, average='macro')\n",
    "    f1_micro = f1_score(true_labels, pred_labels, average='micro')\n",
    "except Exception as e:\n",
    "    logging.error(f\"Ошибка при вычислении F1-score: {e}\")\n",
    "\n",
    "# Расчет по классам\n",
    "f1_class_scores = []\n",
    "for i, cate in enumerate(categories):\n",
    "    try:\n",
    "        score = f1_score(true_labels[:, i], pred_labels[:, i])\n",
    "        f1_class_scores.append(score)\n",
    "        print(f\"F1-score для '{cate}': {score:.4f}\")\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Ошибка при вычислении F1 для '{cate}': {e}\")\n",
    "\n",
    "# Вывод средних значений F1\n",
    "try:\n",
    "    # Среднее по классам (macro уже есть как f1_macro)\n",
    "    print(f\"\\nСредний F1-score (macro): {f1_macro:.4f}\")\n",
    "    print(f\"F1-score (micro): {f1_micro:.4f}\")\n",
    "except NameError:\n",
    "    print(\"Некорректные значения F1-score.\")\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "\n",
    "# ROC-AUC по классам с обработкой ошибок\n",
    "roc_auc_scores = []\n",
    "for i, cate in enumerate(categories):\n",
    "    try:\n",
    "        score = roc_auc_score(true_labels[:, i], preds_array[:, i])\n",
    "        roc_auc_scores.append(score)\n",
    "        print(f\"ROC-AUC для '{cate}': {score:.4f}\")\n",
    "    except ValueError as e:\n",
    "        roc_auc_scores.append(None)\n",
    "        print(f\"ROC-AUC для '{cate}': недоступен ({e})\")\n",
    "        \n",
    "if any(score is not None for score in roc_auc_scores):\n",
    "    valid_scores = [score for score in roc_auc_scores if score is not None]\n",
    "    roc_auc_mean = np.mean(valid_scores) if valid_scores else None\n",
    "else:\n",
    "    roc_auc_mean = None\n",
    "\n",
    "if roc_auc_mean is not None:\n",
    "    print(f\"\\nСредний ROC-AUC по классам: {roc_auc_mean:.4f}\")\n",
    "else:\n",
    "     print(\"\\nНет доступных значений ROC-AUC для вычисления среднего.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
