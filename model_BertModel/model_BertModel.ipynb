{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a61e194",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 254)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mFile \u001b[39m\u001b[32m<tokenize>:254\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mif f1_micro > best_f1_micro:\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# Настройка логирования\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Константы и параметры\n",
    "MODEL_NAME = 'DeepPavlov/rubert-base-cased'\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 256\n",
    "NUM_EPOCHS = 15\n",
    "LEARNING_RATE = 2e-5\n",
    "PATIENCE = 4\n",
    "\n",
    "# Загрузка данных\n",
    "try:\n",
    "    data = pd.read_csv('processed_data.csv')\n",
    "    logging.info(\"Данные успешно загружены.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Ошибка при загрузке данных: {e}\")\n",
    "    raise\n",
    "\n",
    "categories = [\n",
    "    'Вопрос решен',\n",
    "    'Нравится качество выполнения заявки',\n",
    "    'Нравится качество работы сотрудников',\n",
    "    'Нравится скорость отработки заявок',\n",
    "    'Понравилось выполнение заявки',\n",
    "    'Другое'\n",
    "]\n",
    "\n",
    "# Проверка наличия категорий в данных и подготовка меток\n",
    "try:\n",
    "    labels = data[categories].values.astype(int)\n",
    "except KeyError as e:\n",
    "    logging.error(f\"Некоторые категории не найдены в данных: {e}\")\n",
    "    raise\n",
    "\n",
    "# Разделение данных с стратификацией по первому классу для сбалансированности выборки\n",
    "try:\n",
    "    stratify_labels = labels.argmax(axis=1)\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "        data['comment'].values,\n",
    "        labels,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=stratify_labels\n",
    "    )\n",
    "except Exception as e:\n",
    "    logging.error(f\"Ошибка при разделении данных: {e}\")\n",
    "    raise\n",
    "\n",
    "# Инициализация токенизатора\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "class CommentsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=256):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length= max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text= str(self.texts[idx])\n",
    "        label= self.labels[idx]\n",
    "        encoding= self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.FloatTensor(label)\n",
    "        }\n",
    "\n",
    "# Создание датасетов и загрузчиков данных\n",
    "train_dataset = CommentsDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = CommentsDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "# Расчет весов классов для балансировки потерь и выборки (чтобы бороться с дисбалансом)\n",
    "class_counts = train_labels.sum(axis=0)\n",
    "total_samples = len(train_labels)\n",
    "epsilon=1e-6  # чтобы избежать деления на ноль\n",
    "\n",
    "# Используем логарифм для взвешивания (можно оставить или изменить по необходимости)\n",
    "class_weights_np= np.log((total_samples / (class_counts + epsilon)))\n",
    "class_weights_tensor= torch.FloatTensor(class_weights_np).to('cpu')  # для вычислений\n",
    "\n",
    "# Веса для выборки (WeightedRandomSampler) — чтобы сбалансировать обучение по классам\n",
    "sample_weights=[]\n",
    "for label in train_labels:\n",
    "    class_indices= np.where(label==1)[0]\n",
    "    if len(class_indices)>0:\n",
    "        weights_for_classes= class_weights_np[class_indices]\n",
    "        sample_weight= np.min(weights_for_classes)  # можно выбрать среднее или максимум по необходимости\n",
    "    else:\n",
    "        sample_weight=1.0  # если класс отсутствует в примере\n",
    "    \n",
    "    sample_weights.append(sample_weight)\n",
    "\n",
    "sample_weights=np.array(sample_weights)\n",
    "sampler= WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "train_loader= DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler)\n",
    "val_loader= DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Определение модели с несколькими выходами (multi-label classification)\n",
    "class BertMultiLabelClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(MODEL_NAME)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, len(categories))\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output  \n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)  \n",
    "        return logits\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = BertMultiLabelClassifier().to(device)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Исправление: FocalLoss не принимает pos_weight как аргумент конструктора.\n",
    "# Вместо этого используем pos_weight внутри forward.\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha=alpha\n",
    "        self.gamma=gamma\n",
    "        self.reduction=reduction\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        # inputs: logits (не после sigmoid)\n",
    "        # targets: бинарные метки (0 или 1)\n",
    "        \n",
    "        bce_loss=F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        \n",
    "        probs=torch.sigmoid(inputs)\n",
    "        \n",
    "        # Для каждого элемента выбираем prob или 1-prob в зависимости от targets.\n",
    "        pt=torch.where(targets==1., probs, 1.-probs)\n",
    "        \n",
    "        focal_weight=(self.alpha)*(1.-pt)**self.gamma\n",
    "        \n",
    "        loss=focal_weight * bce_loss\n",
    "        \n",
    "        if self.reduction=='mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction=='sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "# Создаем экземпляр потерь без pos_weight (его можно встроить внутри forward при необходимости).\n",
    "criterion=FocalLoss()\n",
    "\n",
    "optimizer=optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "total_steps=len(train_loader)*NUM_EPOCHS\n",
    "\n",
    "scheduler=get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.1*total_steps),\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "best_f1_micro=0\n",
    "epochs_without_improvement=0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss=0\n",
    "    \n",
    "    with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\", unit='batch') as pbar:\n",
    "        for batch in train_loader:\n",
    "            input_ids=batch['input_ids'].to(device)\n",
    "            attention_mask=batch['attention_mask'].to(device)\n",
    "            labels=batch['labels'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs=model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss=criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # градиентный клиппинг\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            total_loss+=loss.item()\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(f\"\\nЭпоха {epoch+1} завершена. Средний Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Валидация и метрики после каждой эпохи\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds=[]\n",
    "    all_true=[]\n",
    "    \n",
    "    for batch in tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}\", unit='batch'):\n",
    "        with torch.no_grad():\n",
    "            input_ids=batch['input_ids'].to(device)\n",
    "            attention_mask=batch['attention_mask'].to(device)\n",
    "\n",
    "            outputs=model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds=torch.sigmoid(outputs).cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_true.extend(batch['labels'].cpu().numpy())\n",
    "\n",
    "    true_labels=np.array(all_true) \n",
    "    preds_array=np.array(all_preds) \n",
    "\n",
    "    pred_labels=(preds_array>=0.5).astype(int)\n",
    "\n",
    "    # В конце каждой эпохи после вычисления F1\n",
    "    try:\n",
    "        f1_micro = f1_score(true_labels, pred_labels, average='micro')\n",
    "        \n",
    "        # Сохраняем модель при улучшении F1 micro.\n",
    "        if f1_micro > best_f1_micro:\n",
    "            best_f1_micro = f1_micro\n",
    "            torch.save(model.state_dict(), 'best_f1micro.pth')\n",
    "        \n",
    "        print(f\"F1-макро на эпохе {epoch+1}: {f1_micro:.4f}\")\n",
    "\n",
    "        for i, cate in enumerate(categories):\n",
    "            score = f1_score(true_labels[:, i], pred_labels[:, i])\n",
    "            print(f\"F1-score для '{cate}': {score:.4f}\")\n",
    "\n",
    "        # Ранняя остановка при отсутствии улучшений по F1 micro.\n",
    "        if f1_micro > best_f1_micro:\n",
    "            epochs_without_improvement = 0  # сбрасываем счетчик при улучшении.\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= PATIENCE:\n",
    "            print(\"Достигнут patience без улучшения — остановка обучения.\")\n",
    "            break\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Ошибка во время оценки или обучения: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1c9adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score для 'Вопрос решен': 0.4950\n",
      "F1-score для 'Нравится качество выполнения заявки': 0.5294\n",
      "F1-score для 'Нравится качество работы сотрудников': 0.8931\n",
      "F1-score для 'Нравится скорость отработки заявок': 0.8987\n",
      "F1-score для 'Понравилось выполнение заявки': 0.4301\n",
      "F1-score для 'Другое': 0.7805\n",
      "\n",
      "Средний F1-score (macro): 0.6711\n",
      "F1-score (micro): 0.7367\n",
      "--------------------------------------------------------------------------\n",
      "ROC-AUC для 'Вопрос решен': 0.7590\n",
      "ROC-AUC для 'Нравится качество выполнения заявки': 0.8845\n",
      "ROC-AUC для 'Нравится качество работы сотрудников': 0.9663\n",
      "ROC-AUC для 'Нравится скорость отработки заявок': 0.9593\n",
      "ROC-AUC для 'Понравилось выполнение заявки': 0.7998\n",
      "ROC-AUC для 'Другое': 0.9196\n",
      "\n",
      "Средний ROC-AUC по классам: 0.8814\n"
     ]
    }
   ],
   "source": [
    "# Оценка модели на валидационной выборке с обработкой ошибок и логированием\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load('best_f1micro.pth'))\n",
    "    logging.info(\"Модель загружена.\")\n",
    "except Exception as e:\n",
    "    logging.warning(f\"Не удалось загрузить модель: {e}\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_true = []\n",
    "\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(val_loader):\n",
    "            try:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].cpu().numpy()\n",
    "\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "\n",
    "                all_preds.extend(preds)\n",
    "                all_true.extend(labels)\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Ошибка при обработке батча {batch_idx}: {e}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Ошибка во время оценки: {e}\")\n",
    "\n",
    "true_labels = np.array(all_true)  # shape: (num_samples,num_classes)\n",
    "preds_array = np.array(all_preds)\n",
    "\n",
    "pred_labels = (preds_array >= 0.5).astype(int)\n",
    "\n",
    "try:\n",
    "    f1_micro = f1_score(true_labels, pred_labels, average='micro')\n",
    "except Exception as e:\n",
    "    logging.error(f\"Ошибка при вычислении F1-score: {e}\")\n",
    "\n",
    "# Расчет по классам\n",
    "f1_class_scores = []\n",
    "for i, cate in enumerate(categories):\n",
    "    try:\n",
    "        score = f1_score(true_labels[:, i], pred_labels[:, i])\n",
    "        f1_class_scores.append(score)\n",
    "        print(f\"F1-score для '{cate}': {score:.4f}\")\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Ошибка при вычислении F1 для '{cate}': {e}\")\n",
    "\n",
    "# Вывод средних значений F1\n",
    "try:\n",
    "    print(f\"F1-score (micro): {f1_micro:.4f}\")\n",
    "except NameError:\n",
    "    print(\"Некорректные значения F1-score.\")\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "\n",
    "# ROC-AUC по классам с обработкой ошибок\n",
    "roc_auc_scores = []\n",
    "for i, cate in enumerate(categories):\n",
    "    try:\n",
    "        score = roc_auc_score(true_labels[:, i], preds_array[:, i])\n",
    "        roc_auc_scores.append(score)\n",
    "        print(f\"ROC-AUC для '{cate}': {score:.4f}\")\n",
    "    except ValueError as e:\n",
    "        roc_auc_scores.append(None)\n",
    "        print(f\"ROC-AUC для '{cate}': недоступен ({e})\")\n",
    "        \n",
    "if any(score is not None for score in roc_auc_scores):\n",
    "    valid_scores = [score for score in roc_auc_scores if score is not None]\n",
    "    roc_auc_mean = np.mean(valid_scores) if valid_scores else None\n",
    "else:\n",
    "    roc_auc_mean = None\n",
    "\n",
    "if roc_auc_mean is not None:\n",
    "    print(f\"\\nСредний ROC-AUC по классам: {roc_auc_mean:.4f}\")\n",
    "else:\n",
    "     print(\"\\nНет доступных значений ROC-AUC для вычисления среднего.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
